{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5324b492-22b2-4f45-9df9-f5e31f4c47b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\hghar\\\\Downloads\\\\DATATHON-2025-main\\\\DATATHON-2025-main\\\\elearning_churn_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0157c25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   User ID                        1000 non-null   object \n",
      " 1   Enrollment Date                1000 non-null   object \n",
      " 2   Subscription Plan              1000 non-null   object \n",
      " 3   Course Completion Rate         1000 non-null   float64\n",
      " 4   Courses Enrolled               1000 non-null   int64  \n",
      " 5   Login Frequency (per month)    1000 non-null   int64  \n",
      " 6   Time Spent per Session (mins)  1000 non-null   float64\n",
      " 7   Last Active Date               1000 non-null   object \n",
      " 8   Forum Participation            1000 non-null   int64  \n",
      " 9   Quiz Participation Rate        1000 non-null   float64\n",
      " 10  Assignment Submission Rate     1000 non-null   float64\n",
      " 11  Video Watch Completion Rate    1000 non-null   float64\n",
      " 12  Survey Response (1-5)          1000 non-null   int64  \n",
      " 13  Feedback Sentiment             1000 non-null   object \n",
      " 14  Support Ticket Sentiment       676 non-null    object \n",
      " 15  Incomplete Courses Count       1000 non-null   int64  \n",
      " 16  Engagement_inper               1000 non-null   float64\n",
      " 17  churn                          1000 non-null   int64  \n",
      " 18  Course Reminder Response       1000 non-null   object \n",
      " 19  Gamified Progress Engagement   1000 non-null   object \n",
      " 20  AI Recommendation Click Rate   1000 non-null   float64\n",
      "dtypes: float64(7), int64(6), object(8)\n",
      "memory usage: 164.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e42905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hghar\\AppData\\Local\\Temp\\ipykernel_18028\\3177323329.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[categorical_cols] = df[categorical_cols].apply(lambda x: x.fillna(method='ffill'))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Handle Missing Values\n",
    "# For numerical columns, we fill with median or mean based on the nature of the column\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# For categorical columns, we fill missing values using forward fill or backward fill\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "df[categorical_cols] = df[categorical_cols].apply(lambda x: x.fillna(method='ffill'))\n",
    "\n",
    "# Handle Duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Feature Engineering\n",
    "# Engagement Score Calculation\n",
    "df['Engagement Score'] = df['Login Frequency (per month)'] * df['Time Spent per Session (mins)']\n",
    "\n",
    "# Encode Categorical Features\n",
    "encoder = LabelEncoder()\n",
    "df['Subscription Plan'] = encoder.fit_transform(df['Subscription Plan'])\n",
    "df['Feedback Sentiment'] = encoder.fit_transform(df['Feedback Sentiment'])\n",
    "df['Support Ticket Sentiment'] = encoder.fit_transform(df['Support Ticket Sentiment'])\n",
    "df['Course Reminder Response'] = encoder.fit_transform(df['Course Reminder Response'])\n",
    "df['Gamified Progress Engagement'] = encoder.fit_transform(df['Gamified Progress Engagement'])\n",
    "\n",
    "# Convert Date columns to datetime\n",
    "df['Enrollment Date'] = pd.to_datetime(df['Enrollment Date'], format='%d-%m-%Y')\n",
    "df['Last Active Date'] = pd.to_datetime(df['Last Active Date'], format='%d-%m-%Y')\n",
    "\n",
    "# Calculate the days since last active\n",
    "df['Days Since Last Active'] = (pd.to_datetime('today') - df['Last Active Date']).dt.days\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Separate Independent Variables and Target Variable\n",
    "X = df.drop(['churn'], axis=1)  # Independent features\n",
    "y = df['churn']  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1674fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['churn'].astype(int)  # Ensure the churn column is in integer format (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d862269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\hghar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\hghar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\hghar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost) (1.15.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05de04cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hghar\\AppData\\Local\\Temp\\ipykernel_18028\\1414443987.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_churn['Subscription Plan'] = X_churn['Subscription Plan'].astype('category').cat.codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier - Churn Prediction\n",
      "[[117  19]\n",
      " [ 44  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       136\n",
      "           1       0.51      0.31      0.39        64\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.62      0.59      0.59       200\n",
      "weighted avg       0.66      0.69      0.66       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Convert the 'churn' column to binary if necessary\n",
    "y = df['churn'].astype(int)\n",
    "\n",
    "# Features to use for churn prediction\n",
    "X_churn = df[['Subscription Plan', 'Course Completion Rate', 'Survey Response (1-5)', 'Time Spent per Session (mins)',\n",
    "              'Assignment Submission Rate', 'Video Watch Completion Rate', 'Engagement Score']]\n",
    "\n",
    "# Encode categorical variables (if necessary)\n",
    "X_churn['Subscription Plan'] = X_churn['Subscription Plan'].astype('category').cat.codes\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_churn, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"XGBoost Classifier - Churn Prediction\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f09facf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XGBoost Classifier - Churn Prediction\n",
      "[[117  19]\n",
      " [ 44  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       136\n",
      "           1       0.51      0.31      0.39        64\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.62      0.59      0.59       200\n",
      "weighted avg       0.66      0.69      0.66       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(xgb_model, 'xgb_churn_model.pkl')\n",
    "\n",
    "# Load the XGBoost model\n",
    "loaded_model = joblib.load('xgb_churn_model.pkl')\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Loaded XGBoost Classifier - Churn Prediction\")\n",
    "print(confusion_matrix(y_test, y_pred_loaded))\n",
    "print(classification_report(y_test, y_pred_loaded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3b2a702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Smruti Deshpande\\AppData\\Local\\Temp\\ipykernel_8624\\3484681465.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_churn['Subscription Plan'] = X_churn['Subscription Plan'].astype('category').cat.codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Classifier - Churn Prediction\n",
      "[[133   3]\n",
      " [ 62   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.98      0.80       136\n",
      "           1       0.40      0.03      0.06        64\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.54      0.50      0.43       200\n",
      "weighted avg       0.59      0.68      0.57       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Convert the 'churn' column to binary if necessary\n",
    "y = df['churn'].astype(int)\n",
    "\n",
    "# Features to use for churn prediction\n",
    "X_churn = df[['Subscription Plan', 'Course Completion Rate', 'Survey Response (1-5)', 'Time Spent per Session (mins)',\n",
    "              'Assignment Submission Rate', 'Video Watch Completion Rate', 'Engagement Score']]\n",
    "\n",
    "# Encode categorical variables (if necessary)\n",
    "X_churn['Subscription Plan'] = X_churn['Subscription Plan'].astype('category').cat.codes\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_churn, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the CatBoost model\n",
    "catboost_model = CatBoostClassifier(iterations=100, random_state=42, verbose=0)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = catboost_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"CatBoost Classifier - Churn Prediction\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c93b28ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hghar\\AppData\\Local\\Temp\\ipykernel_18028\\2139652118.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_churn['Subscription Plan'] = X_churn['Subscription Plan'].astype('category').cat.codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'scale_pos_weight': 1}\n",
      "\n",
      "Average Accuracy from 10-Fold Cross-Validation: 0.7275\n",
      "Confusion Matrix:\n",
      "[[130   6]\n",
      " [ 22 122]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.90       136\n",
      "           1       0.95      0.85      0.90       144\n",
      "\n",
      "    accuracy                           0.90       280\n",
      "   macro avg       0.90      0.90      0.90       280\n",
      "weighted avg       0.91      0.90      0.90       280\n",
      "\n",
      "\n",
      "Accuracy: 0.9000\n",
      "\n",
      "Predicted vs Actual (first 10 examples):\n",
      "      Actual  Predicted\n",
      "78         0          0\n",
      "478        0          0\n",
      "354        1          1\n",
      "594        1          1\n",
      "1255       1          1\n",
      "993        0          0\n",
      "254        0          0\n",
      "567        1          0\n",
      "316        1          0\n",
      "1131       1          1\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert the 'churn' column to binary if necessary\n",
    "y = df['churn'].astype(int)\n",
    "\n",
    "# Features to use for churn prediction\n",
    "X_churn = df[['Subscription Plan', 'Course Completion Rate', 'Survey Response (1-5)', 'Time Spent per Session (mins)',\n",
    "              'Assignment Submission Rate', 'Video Watch Completion Rate', 'Engagement Score']]\n",
    "\n",
    "# Encode categorical variables (if necessary)\n",
    "X_churn['Subscription Plan'] = X_churn['Subscription Plan'].astype('category').cat.codes\n",
    "\n",
    "# Handle class imbalance using SMOTE (oversampling the minority class)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_churn_resampled, y_resampled = smote.fit_resample(X_churn, y)\n",
    "\n",
    "# Train-Test Split (we will use cross-validation for model evaluation instead)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_churn_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'scale_pos_weight': [1, 10]  # Adjust this to handle class imbalance\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb.XGBClassifier(random_state=42), param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from GridSearchCV\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# Train the XGBoost model using the best parameters\n",
    "xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# 10-fold Cross-Validation to evaluate the model performance\n",
    "skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "accuracies = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_churn_resampled, y_resampled):\n",
    "    X_train_cv, X_test_cv = X_churn_resampled.iloc[train_idx], X_churn_resampled.iloc[test_idx]\n",
    "    y_train_cv, y_test_cv = y_resampled.iloc[train_idx], y_resampled.iloc[test_idx]\n",
    "\n",
    "    # Fit the model on the current fold\n",
    "    xgb_model.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_cv = xgb_model.predict(X_test_cv)\n",
    "    \n",
    "    # Calculate accuracy for the fold\n",
    "    accuracies.append(accuracy_score(y_test_cv, y_pred_cv))\n",
    "\n",
    "print(f\"\\nAverage Accuracy from 10-Fold Cross-Validation: {np.mean(accuracies):.4f}\")\n",
    "\n",
    "# Now, train the model on the full resampled dataset for final evaluation\n",
    "xgb_model.fit(X_churn_resampled, y_resampled)\n",
    "\n",
    "# Save the trained model using joblib\n",
    "joblib.dump(xgb_model, 'xgb_churn_model.pkl')\n",
    "\n",
    "# Load the model from the saved file\n",
    "loaded_model = joblib.load('xgb_churn_model.pkl')\n",
    "\n",
    "# Predictions with the loaded model\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "\n",
    "# Evaluate model predictions\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_loaded))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_loaded))\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy = accuracy_score(y_test, y_pred_loaded)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Optional: Display some predicted vs actual values\n",
    "predicted_vs_actual = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_loaded})\n",
    "print(\"\\nPredicted vs Actual (first 10 examples):\")\n",
    "print(predicted_vs_actual.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a801567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Churn Rate: 45.71%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the predicted churn rate\n",
    "predicted_churns = sum(y_pred_loaded)  # Count the number of predicted churns (1's)\n",
    "total_predictions = len(y_pred_loaded)  # Total number of predictions\n",
    "\n",
    "# Churn Rate (as percentage)\n",
    "churn_rate = (predicted_churns / total_predictions) * 100\n",
    "\n",
    "print(f\"Predicted Churn Rate: {churn_rate:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
